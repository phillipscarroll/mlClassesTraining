{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 3 A Tour of Machine Learning Classifier Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each classification algorithm has its tradeoff, no ML free lunch.\n",
    "\n",
    "No single classifier works for all situations.\n",
    "\n",
    "You must experiment and see which classifier works best for your project, although there is a mountain of data out there to point you in the right direction to shortcut much of this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The power of a classifier depends on the data available for learning.\n",
    "\n",
    "* Training\n",
    "  * Selecting features and collecting labeled training examples\n",
    "  * Choose a performance metric\n",
    "  * Choose a learning algorithm and training a model\n",
    "  * Evaluation the performance of a model\n",
    "  * Changing the settings and tuning the model\n",
    "\n",
    "Page 54"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit gives us an API to easily leverage models like preceptron and Adaline for testing. It also includes many functions and convenience features. \n",
    "\n",
    "Lets training some more perceptron models with the Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "iris = datasets.load_iris() # datasets contains a number of sample datasets from sklearn\n",
    "X = iris.data[:, [2, 3]] # : means all rows, [2, 3] means columns 2 and 3 of the iris data\n",
    "y = iris.target # target is the class labels\n",
    "# X is the features or data, y is the class labels or target\n",
    "\n",
    "# Print the class labels, deduplicated\n",
    "print('Class labels:', np.unique(y)) # We use numpy's unique method to deduplicate the iris targets in y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is best practice to utilizer numerical values for class labels to avoid technical issues and increase training/testing speed.\n",
    "\n",
    "Lets split the dataset into a train and test dataset. Scikit Learn has a function for this we can import. We want to randomly split the X and y arrays into 30% test data and 70% training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [50 50 50]\n",
      "Lanels counts in y_train: [35 35 35]\n",
      "Labels counts in y_test: [15 15 15]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "# stratify=y means that the class labels are distributed in the training and test sets as they are in the original dataset\n",
    "\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Lanels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
